#!/bin/bash
#SBATCH --job-name=single_source_p_low
#SBATCH --array=1-128
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --time=0-01:00:00
#SBATCH --mem-per-cpu=800MB
#SBATCH --err=slurm_%A-%a.err
#SBATCH --out=slurm_%A-%a.out
#SBATCH --partition=g100_usr_prod
#SBATCH --qos=g100_qos_dbg

#export SBP_NUM_THREADS=2
export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}
export SBP_PATH=${HOME}/Projects/sbp-transparency
export SBP_CACHE_PATH=$SCRATCH/single-source-p-low
mkdir -p ${SBP_CACHE_PATH}

# Define and create a unique scratch directory

echo "Processing task with scratch dir " ${SBP_CACHE_PATH}

module purge
eval "$(conda shell.bash hook)"
conda activate sbp

module load intel/oneapi-2022--binary intel-oneapi-compilers/2021.4.0

export DEVITO_ARCH=intel
export DEVITO_PLATFORM=intel64
export DEVITO_LANGUAGE=openmp
export DEVITO_OPT=advanced
export DEVITO_AUTOTUNING=aggressive
export DEVITO_LOGGING=INFO
export KMP_AFFINITY=compact

# Each job will see a different ${SLURM_ARRAY_TASK_ID}
srun --cpu-bind=cores -m block:block python forward_model.py

# Happy ending
exit 0